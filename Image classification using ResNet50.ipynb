{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnt7EhEiut7K"
   },
   "source": [
    "# Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fFmW2sxG5zD"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zNhQRUru1Pc"
   },
   "source": [
    "## Import data from directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RIqaIlXva_D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_id = []\n",
    "object_type = []\n",
    "dir = '/content/drive/MyDrive/data/'\n",
    "for dirname in os.listdir(dir):\n",
    "    if dirname!='.DS_Store':\n",
    "        for filename in os.listdir(dir+dirname):\n",
    "              image_id.append(dir+dirname+'/'+filename)\n",
    "              object_type.append(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c85gdiw7SjI0",
    "outputId": "096c3df3-03aa-404e-8bcd-9b287c70bad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZijNWrRvafO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(image_id, object_type)),columns = ['ImageID','Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXWpXqoTgwtF"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x58i6KiOvVyQ"
   },
   "outputs": [],
   "source": [
    "inp = df['ImageID']\n",
    "out = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1CL6PQiG0ro"
   },
   "outputs": [],
   "source": [
    "train_in,test_in,train_out,test_out = train_test_split(inp,out,random_state = 42,test_size = 0.2,stratify = out)      #splitting the data set   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an object from image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrycWWYKHecw"
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "                    rotation_range = 40,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    vertical_flip = True,\n",
    "                    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catenation of training input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7ucLgBlHgIc"
   },
   "outputs": [],
   "source": [
    "train_x = pd.concat([train_in,train_out],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsMsoIhel0qr",
    "outputId": "51a3873e-4da6-4391-c6b6-37fa6ababa46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'cat': 1185, 'kenye west': 1245, 'pikachu': 1040})"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "Counter(object_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train images from whole dataset remain after spiliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuPwih4QHiaB",
    "outputId": "68391633-2573-4667-e464-593efd1dddb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2776 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_gen.flow_from_dataframe(\n",
    "                    train_x ,x_col = \"ImageID\",y_col = \"Type\",\n",
    "                    target_size = (200,200),\n",
    "                    batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancatinate the test input and test output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrN57COFHjx8"
   },
   "outputs": [],
   "source": [
    "test_x = pd.concat([test_in,test_out],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of image for  validation after splittting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Kh8iSODHoo7",
    "outputId": "1a4dc150-3928-462d-bc83-ab6119cb7c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = data_gen.flow_from_dataframe(\n",
    "                    test_x,x_col = \"ImageID\",y_col = \"Type\",\n",
    "                    target_size = (200,200),\n",
    "                    batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8tvYoAju-ac"
   },
   "source": [
    "## Model - Using ResNET50 as transfer learining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_pbkKmjHtA2",
    "outputId": "e64ceec8-a33d-4031-dd92-1b782ab4b726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(ResNet50(input_shape = (200,200, 3), include_top = False, weights = 'imagenet'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complile of model with categorical crossentropy and adam optimizer with learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuK9wGvwHwYR"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = Adam(learning_rate = 0.001),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model with epoch 10 and batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KvhG8BEHx2X",
    "outputId": "a609fe79-9f79-4e74-b2a7-7d486debcb71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 617s 14s/step - loss: 11.2146 - accuracy: 0.7313 - val_loss: 49.1269 - val_accuracy: 0.5072\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.5351 - accuracy: 0.8894 - val_loss: 120.7422 - val_accuracy: 0.4914\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.2139 - accuracy: 0.9282 - val_loss: 27.6346 - val_accuracy: 0.7435\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.1881 - accuracy: 0.9362 - val_loss: 0.6941 - val_accuracy: 0.8790\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 45s 1s/step - loss: 0.1028 - accuracy: 0.9648 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 45s 1s/step - loss: 0.0758 - accuracy: 0.9734 - val_loss: 0.1150 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 0.0805 - val_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.0638 - accuracy: 0.9782 - val_loss: 0.2115 - val_accuracy: 0.9568\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.0856 - accuracy: 0.9720 - val_loss: 1.4693 - val_accuracy: 0.7925\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.0881 - accuracy: 0.9741 - val_loss: 0.3040 - val_accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,epochs = 10,\n",
    "                    validation_data = val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XBTq6g1vHuQ"
   },
   "source": [
    "## Prediction on Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmWiqMIMkvnR",
    "outputId": "6f15a0ff-cb6d-4b2d-b503-dad40ffd5b82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 1,\n",
       "       0, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 2, 1, 2,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 0, 2, 1, 1,\n",
       "       2, 0, 0, 1, 0, 1, 2, 1, 0, 0, 2, 1, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2,\n",
       "       1, 2, 0, 2, 2, 2, 1, 2, 1, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1,\n",
       "       0, 2, 1, 0, 2, 0, 1, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 1,\n",
       "       0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 2, 2, 1, 0,\n",
       "       1, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 0, 2, 1,\n",
       "       1, 1, 2, 2, 0, 2, 2, 1, 0, 2, 0, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 0,\n",
       "       1, 1, 0, 1, 2, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
       "       1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 2, 0, 2, 2, 0, 1, 2,\n",
       "       1, 2, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 2, 2, 1, 1, 2, 0, 0, 2, 1, 2, 2, 0, 1, 1, 2,\n",
       "       0, 2, 0, 0, 2, 2, 1, 1, 2, 1, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0,\n",
       "       0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 2, 2, 0, 2, 2, 0, 2,\n",
       "       0, 1, 1, 2, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 2, 2, 0, 2, 2, 0,\n",
       "       0, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 2, 2, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 1,\n",
       "       1, 2, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 1,\n",
       "       2, 1, 2, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 0,\n",
       "       2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 0, 0, 1,\n",
       "       0, 2, 1, 0, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 0,\n",
       "       0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 1, 0, 0, 2, 0, 2, 0, 1, 1,\n",
       "       2, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 0, 0, 0, 1,\n",
       "       2, 1, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1,\n",
       "       1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= model.predict_classes(val_generator)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping of array with their lables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CDhnEJRk-iM"
   },
   "outputs": [],
   "source": [
    "pred_1= pd.Series(pred).map({0:'Cat', 1:'kenye west',2:'pikachu'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the image with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj0Pmc1ZHy_b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict(path):\n",
    "  img = image.load_img(path=path ,target_size=(200, 200,3))\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_batch = np.expand_dims(img_array, axis=0)\n",
    "  pred = model.predict(img_batch)\n",
    "  prediction= np.argmax(pred,axis=1)\n",
    "  class_indices = list(val_generator.class_indices.keys())\n",
    "  return (class_indices[prediction[0]],max(pred[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t24W1_qBp-uO",
    "outputId": "dc299e52-f632-4a4d-ecbc-30001f457446"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('kenye west', 99.9506950378418)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('/content/drive/MyDrive/data/kenye west/1000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMzUrqgOyPoR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "output = []\n",
    "for x in test_in:\n",
    "  output.append(predict(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print 10 predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKzGIJsEyvrw",
    "outputId": "ce4b058b-b417-4fa7-c7a2-3b12c7486e53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu',\n",
       " 'kenye west',\n",
       " 'kenye west',\n",
       " 'cat',\n",
       " 'kenye west',\n",
       " 'cat',\n",
       " 'kenye west',\n",
       " 'kenye west',\n",
       " 'cat',\n",
       " 'cat']"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data_X_image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
